{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Edit Metadata",
    "colab": {
      "name": "simple_text_mining_exercise.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey1n-XCB9yYT",
        "outputId": "ef810666-a214-4e61-84f9-c4b16dc9c8e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "GzY2TEr9G-Zg"
      },
      "source": [
        "# A. Klasifikasi gender dari profil user Twitter\n",
        "\n",
        "Tutorial ini menggunakan <i>dataset</i> dari <a href='https://www.kaggle.com/efeergun96/classification-by-tweets-nlp'>Kaggle</a> yang telah dimodifikasi untuk mengklasifikasikan <i>gender</i> pengguna Twitter. <i>Dataset</i> ini memuat informasi pengguna Twitter dan juga sampel <i>tweet</i>. Tabel 1 merangkum informasi atribut pada <i>dataset</i> yang digunakan pada tutorial ini (<i>data_gender.csv</i>). \n",
        "\n",
        "Tabel 1. Informasi Atribut pada <i>Dataset data_gender.csv</i>\n",
        "\n",
        "|Nama Atribut|Jenis Data|Keterangan| \n",
        "|------|------|------|\n",
        "|<i>gender</i>|kategorikal|gender penggunan Twitter, akan digunakan sebagai label|\n",
        "|<i>fav_number</i>|numerik|jumlah tweet yang difavoritkan oleh pengguna|\n",
        "|<i>link_color</i>|kategorikal|warna link pada profil pengguna, dituliskan dalam hex code|\n",
        "|<i>retweet_count</i>|numerik|jumlah tweet yang di-retweet oleh pengguna|\n",
        "|<i>sidebar_color</i>|kategorikal|warna sidebar pada profil pengguna, dituliskan dalam hex code|\n",
        "|<i>tweet_count</i>|numerik|jumlah tweet yang ditulis oleh pengguna|\n",
        "|<i>user_timezone</i>|kategorikal|jenis zona waktu pengguna|\n",
        "\n",
        "Langkah-langkah untuk mengklasifikasikan <i>gender</i> dari <i>dataset</i> tersebut adalah sebagai berikut:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "3fxQs2Lc8zMT"
      },
      "source": [
        "<b>1. Membaca data</b><br>\n",
        "Library pandas digunakan untuk membaca <i>dataset</i>. Tipe data yang terbentuk setelah membaca berkas csv menggunakan fungsi $read\\_csv$ dari pandas adalah <i>dataframe</i>. Untuk mengetahui dimensi dari <i>dataframe</i> yang terbentuk, dapat digunakan properti $shape$. Sementara itu, $data.head()$ digunakan untuk menampilkan sampel data (5 teratas). \n",
        "\n",
        "<b>#Code 1</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:41:25.311818Z",
          "start_time": "2020-05-14T03:41:25.008496Z"
        },
        "id": "QQ5cqv6zG-Zh",
        "outputId": "32c0b1c3-23ce-4cd8-b6bc-49f0a11476dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# membaca data menggunakan pandas\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/dataset/gender-data.csv', delimiter=',')\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6323, 7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>fav_number</th>\n",
              "      <th>link_color</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>sidebar_color</th>\n",
              "      <th>tweet_count</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>08C2C2</td>\n",
              "      <td>0</td>\n",
              "      <td>FFFFFF</td>\n",
              "      <td>110964</td>\n",
              "      <td>Chennai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>37318</td>\n",
              "      <td>3B94D9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31462</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>female</td>\n",
              "      <td>3901</td>\n",
              "      <td>F5ABB5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20036</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>female</td>\n",
              "      <td>1825</td>\n",
              "      <td>9266CC</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>482</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>female</td>\n",
              "      <td>3115</td>\n",
              "      <td>9266CC</td>\n",
              "      <td>0</td>\n",
              "      <td>FFFFFF</td>\n",
              "      <td>26085</td>\n",
              "      <td>Amsterdam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender  fav_number  ... tweet_count               user_timezone\n",
              "0    male           0  ...      110964                     Chennai\n",
              "1  female       37318  ...       31462                           -\n",
              "2  female        3901  ...       20036  Central Time (US & Canada)\n",
              "3  female        1825  ...         482                           -\n",
              "4  female        3115  ...       26085                   Amsterdam\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-27T15:14:09.429391Z",
          "start_time": "2020-04-27T15:14:09.425721Z"
        },
        "editable": false,
        "id": "5egRs3Ou8zMs"
      },
      "source": [
        "<b>2. Fungsi $describe()$</b><br>\n",
        "Fungsi $describe()$ digunakan untuk menampilkan gambaran statistik singkat dari keseluruhan data atau kolom/fitur tertentu dari data.\n",
        "\n",
        "<b>#Code 2</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:41:28.414021Z",
          "start_time": "2020-05-14T03:41:28.318438Z"
        },
        "id": "Fau-87StG-Zm",
        "outputId": "ba4991ab-e94b-4e9c-d4ee-adf54fb0b7a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fav_number</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>tweet_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6323.000000</td>\n",
              "      <td>6323.000000</td>\n",
              "      <td>6.323000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7213.308082</td>\n",
              "      <td>0.099004</td>\n",
              "      <td>3.454298e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>15519.930249</td>\n",
              "      <td>2.148255</td>\n",
              "      <td>7.721278e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>329.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.245000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1951.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.333100e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7149.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.736200e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>341621.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>2.680199e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          fav_number  retweet_count   tweet_count\n",
              "count    6323.000000    6323.000000  6.323000e+03\n",
              "mean     7213.308082       0.099004  3.454298e+04\n",
              "std     15519.930249       2.148255  7.721278e+04\n",
              "min         0.000000       0.000000  1.000000e+00\n",
              "25%       329.000000       0.000000  4.245000e+03\n",
              "50%      1951.000000       0.000000  1.333100e+04\n",
              "75%      7149.000000       0.000000  3.736200e+04\n",
              "max    341621.000000     153.000000  2.680199e+06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "MlHX5end8zM4"
      },
      "source": [
        "Fungsi $describe()$ akan menampilkan statistik standar (<i>mean</i>, <i>std</i>, <i>min</i>, <i>max</i>) untuk kolom/atribut bertipe kuantitatif (numerik), sedangkan untuk kolom bertipe kualitatif  (kategorikal) maka informasi yang akan ditampilkan berupa:\n",
        "* count: Jumlah <i>filled in</i>/ row yang terisi\n",
        "* unique: Berapa banyak nilai unik/level\n",
        "* top: Nama item yang paling banyak muncul dalam data\n",
        "* Freq: Seberapa sering top item umum muncul dalam data\n",
        "\n",
        "contoh:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:41:31.166982Z",
          "start_time": "2020-05-14T03:41:31.152723Z"
        },
        "id": "ncoKhFaZG-Zp",
        "outputId": "da3c7a01-032d-4193-841a-b549f673be2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data['sidebar_color'].value_counts(dropna=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         2702\n",
              "FFFFFF    2662\n",
              "181A1E     236\n",
              "65B0DA     155\n",
              "5ED4DC     143\n",
              "A8C7F7     142\n",
              "BDDCAD      83\n",
              "CC3366      78\n",
              "DFDFDF      53\n",
              "DBE9ED      51\n",
              "F0A830      14\n",
              "80808        4\n",
              "Name: sidebar_color, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "TLLOCeys8zNF"
      },
      "source": [
        "<b>3. Transformasi data kategorikal ke numerik</b><br>\n",
        "Atribut kategorikal perlu ditransformasi ke dalam bentuk numerik untuk bisa digunakan sebagai fitur dalam klasifikasi. Proses <i>encoding</i> dari data kategorikal ke dalam data numerik dapat dilakukan dengan properti <i>cat.codes</i>.\n",
        "\n",
        "<b>#Code 3a</b><br>\n",
        "Menampilkan tipe data sebelum transformasi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:41:33.571973Z",
          "start_time": "2020-05-14T03:41:33.558940Z"
        },
        "id": "XiO0X_bgG-Zt",
        "outputId": "f9000c0e-b7df-4b43-f7a5-065e98e05eaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# tipe data column sebelum transformasi\n",
        "\n",
        "print(\"Column Data Type before transformation \\n\" + str(data.dtypes))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column Data Type before transformation \n",
            "gender           object\n",
            "fav_number        int64\n",
            "link_color       object\n",
            "retweet_count     int64\n",
            "sidebar_color    object\n",
            "tweet_count       int64\n",
            "user_timezone    object\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "jK7u6uq78zNR"
      },
      "source": [
        "<b>#Code 3b</b><br>\n",
        "Mengubah semua kolom dengan tipe “object” ke dalam bentuk “category”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:41:35.306049Z",
          "start_time": "2020-05-14T03:41:35.128490Z"
        },
        "id": "uMStExI7G-Zw",
        "outputId": "624f64ed-cfb8-4807-85a3-e447b059248b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data[data.select_dtypes(['object']).columns] = data.select_dtypes(\n",
        "    ['object']).apply(lambda x: x.astype('category'))\n",
        "\n",
        "print(\"Column Data Type After Transformation\\n\" + str(data.dtypes))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column Data Type After Transformation\n",
            "gender           category\n",
            "fav_number          int64\n",
            "link_color       category\n",
            "retweet_count       int64\n",
            "sidebar_color    category\n",
            "tweet_count         int64\n",
            "user_timezone    category\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "7IqVfMye8zNZ"
      },
      "source": [
        "<b>#Code 3c</b><br>\n",
        "Melakukan <i>encoding data</i> kategorikal ke dalam tipe data numerik dengan cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:41:37.281578Z",
          "start_time": "2020-05-14T03:41:37.248134Z"
        },
        "id": "A9ltLLeIG-Zz",
        "scrolled": true,
        "outputId": "a93c2eaa-b301-4eef-e035-451b73fc1a43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "data[data.select_dtypes(['category']).columns] = data.select_dtypes(\n",
        "    ['category']).apply(lambda x: x.cat.codes)\n",
        "\n",
        "print(\"Column Data Type After Transformation\\n\" + str(data.dtypes))\n",
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column Data Type After Transformation\n",
            "gender            int8\n",
            "fav_number       int64\n",
            "link_color       int16\n",
            "retweet_count    int64\n",
            "sidebar_color     int8\n",
            "tweet_count      int64\n",
            "user_timezone    int16\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>fav_number</th>\n",
              "      <th>link_color</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>sidebar_color</th>\n",
              "      <th>tweet_count</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>110964</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>37318</td>\n",
              "      <td>536</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31462</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3901</td>\n",
              "      <td>1495</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20036</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1825</td>\n",
              "      <td>972</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>482</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3115</td>\n",
              "      <td>972</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>26085</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender  fav_number  link_color  ...  sidebar_color  tweet_count  user_timezone\n",
              "0       1           0         130  ...             11       110964             40\n",
              "1       0       37318         536  ...              0        31462              0\n",
              "2       0        3901        1495  ...              0        20036             39\n",
              "3       0        1825         972  ...              0          482              0\n",
              "4       0        3115         972  ...             11        26085             11\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "XVAGDwtM8zNm"
      },
      "source": [
        "<b>4. Mendefinisikan fitur dan label</b><br>\n",
        "Pada tutorial ini, dari 6 fitur  kita hanya menggunakan 3 fitur yang meliputi $link\\_color$, $sidebar\\_color$, dan $tweet\\_count$ dalam melakukan klasifikasi <i>gender</i>. Kolom <i>gender</i> digunakan sebagai label.\n",
        "\n",
        "<b>#Code 4</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:41:44.031038Z",
          "start_time": "2020-05-14T03:41:44.016746Z"
        },
        "id": "W4gxdb8-G-Z2"
      },
      "source": [
        "# mendefinisikan fitur dan label\n",
        "\n",
        "feat_column = ['link_color', 'sidebar_color', 'tweet_count']\n",
        "feat = data[feat_column]\n",
        "label = data['gender']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "GTkRmuWH8zNs"
      },
      "source": [
        "<b>5. Pembagian Data, Training dan Testing</b><br>\n",
        "Pada percobaan ini, dilakukan pembagian proporsi 90:10 dimana 90% dibagi menjadi data training dan 10% menjadi data testing. Multinomial Naïve Bayes digunakan untuk membentuk model yang mempelajari data training. Selanjutnya, model yang dibangun digunakan untuk memprediksi data testing yang tidak berlabel.\n",
        "\n",
        "<b>#Code 5a</b><br>\n",
        "Melakukan <i>import model selection</i>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:41:49.792558Z",
          "start_time": "2020-05-14T03:41:45.834030Z"
        },
        "id": "1YCb6HRXG-Z6"
      },
      "source": [
        "# import model selection\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "Mhs5nPY58zN3"
      },
      "source": [
        "<b>#Code 5b</b><br>\n",
        "Pembagian data dengan proporsi 90:10 untuk <i>training</i> dan <i>testing</i> model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:41:51.090682Z",
          "start_time": "2020-05-14T03:41:51.073626Z"
        },
        "id": "5Di9nz3eG-Z9",
        "outputId": "cf306a53-9c55-4ce2-fb06-b9ff9d9d0db9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# pembagian data dengan proporsi 90:10\n",
        "\n",
        "train_feat, test_feat, train_labels, test_labels = train_test_split(\n",
        "    feat, label, test_size=0.1, random_state=150)\n",
        "\n",
        "print(train_feat.shape)\n",
        "print(test_feat.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5690, 3)\n",
            "(633, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "z6jsOfVJ8zOC"
      },
      "source": [
        "<b>#Code 5c</b><br>\n",
        "<i>Training</i> dan <i>testing</i> model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:41:53.284205Z",
          "start_time": "2020-05-14T03:41:52.720696Z"
        },
        "id": "HKcUmCMAG-aA"
      },
      "source": [
        "# inisiasi jenis classifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "NB = MultinomialNB()\n",
        "\n",
        "# training classifier\n",
        "classifier_model = NB.fit(train_feat, train_labels)\n",
        "\n",
        "# prediksi data testing\n",
        "pred = classifier_model.predict(test_feat)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "h5a5ejLU8zOL"
      },
      "source": [
        "<b>6. Evaluasi</b><br>\n",
        "Secara umum, evaluasi pada klasifikasi diukur dengan menggunakan akurasi.\n",
        "Akurasi dihitung berdasarkan jumlah data yang diprediksi benar dibagi dengan total\n",
        "data yang diuji secara keseluruhan. Namun ada pula beberapa metrik evaluasi yang\n",
        "lain, misalnya <i>precision</i> dan <i>recall</i>.\n",
        "\n",
        "<b>#Code 6</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:41:54.718609Z",
          "start_time": "2020-05-14T03:41:54.632640Z"
        },
        "id": "SsDNc0VdG-aC",
        "outputId": "601c73e8-640c-4702-becb-8c64c79fab88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
        "\n",
        "print(\"Akurasi = \", accuracy_score(test_labels, pred))\n",
        "print(\"Precision = \", precision_score(test_labels, pred))\n",
        "print(\"Recall = \", recall_score(test_labels, pred))\n",
        "\n",
        "print(confusion_matrix(test_labels, pred))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Akurasi =  0.5497630331753555\n",
            "Precision =  0.4745098039215686\n",
            "Recall =  0.44485294117647056\n",
            "[[227 134]\n",
            " [151 121]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "LtxwBPiH8zOX"
      },
      "source": [
        "<b>7. Visualisasi Confusion Matrix</b><br>\n",
        "Visualisasi digunakan untuk memudahkan pembacaan <i>confusion matrix</i>. <i>Source code</i> visualisasi confusion matrix dapat didapatkan dari halaman resmi <a href='https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html'>scikit-learn</a>.\n",
        "\n",
        "<b><font color='red'>Tugas Tutorial A</font></b>\n",
        "1. Buatlah visualisasi <i>confusion matrix</i> yang dinormalisasi dari hasil prediksi pada data testing. Buatlah interpretasi dari <i>confusion matrix</i> tersebut. \n",
        "2. Lakukan percobaan klasifikasi data <i>gender</i> tersebut dengan model klasifikasi yang lain, yaitu:\n",
        "    * Logistic Regression jika nama lengkap Anda dimulai dengan huruf A-I \n",
        "    * Decision Tree jika nama lengkap Anda dimulai dengan huruf J-R\n",
        "    * K-Nearest Neighbor dengan jumlah $k=5$ jika nama lengkap Anda dimulai dengan huruf S-Z\n",
        "    \n",
        "  Lakukan evaluasi dengan parameter akurasi, <i>precision</i>, <i>recall</i>, dan F1-score. Bandingkan hasil evaluasi tersebut terhadap model Multinomial Naive Bayes yang kita gunakan sebelumnya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11pDZ0mgCHGj"
      },
      "source": [
        "**Jawaban Tugas A**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKu4N4JDEGlR"
      },
      "source": [
        "__No. 1__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k6BNcT0EF8l",
        "outputId": "bfee9e7b-e556-4385-bd98-1c0487179741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "conf_mat = confusion_matrix(test_labels, pred)\n",
        "\n",
        "disp = plot_confusion_matrix(classifier_model, test_feat, test_labels, cmap=plt.cm.Blues, normalize='true')\n",
        "disp.ax_.set_title(\"Confusion Matrix\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcuLKwI9Hgd1"
      },
      "source": [
        "Dari *confusion matrix* di atas, dapat dilihat bahwa *True Negatives (TN)* bernilai 0.63 dan *True Positives (TP)* bernilai 0.44. Selain itu, *False Negatives (TP)* bernilai 0.56 dan *False Positives (FP)* bernilai 0.37. Dengan nilai FN yang relatif tinggi mengindikasikan model gagal mendeteksi gender pria justru dideteksi sebagai wanita, serta FP yang juga relatif tinggi yang mengindikasikan model juga kurang baik mendeteksi gender wanita yang justru dideteksi sebagai pria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvOWPKGvEAis"
      },
      "source": [
        "__No. 2__\n",
        "<br/>\n",
        "*Nama lengkap dimulai huruf M -> __Decision Tree__*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5-DfwukCNe1"
      },
      "source": [
        "# inisiasi jenis classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "DTC = DecisionTreeClassifier()\n",
        "\n",
        "# training classifier\n",
        "classifier_model_DTC = DTC.fit(train_feat, train_labels)\n",
        "\n",
        "# prediksi data testing\n",
        "pred_DTC = classifier_model.predict(test_feat)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Reqe7DiXJqtB",
        "outputId": "58cbfb27-a86d-4f34-b570-43fcac37e425",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(\"Akurasi = \", accuracy_score(test_labels, pred_DTC))\n",
        "print(\"Precision = \", precision_score(test_labels, pred_DTC))\n",
        "print(\"Recall = \", recall_score(test_labels, pred_DTC))\n",
        "print(\"F1 Score = \", f1_score(test_labels, pred_DTC))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Akurasi =  0.5497630331753555\n",
            "Precision =  0.4745098039215686\n",
            "Recall =  0.44485294117647056\n",
            "F1 Score =  0.45920303605313095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43wDQkWCKYYS"
      },
      "source": [
        "Jika dibandingkan dengan Multinomial NB, Decision Tree Classifier cenderung menghasilkan performa yang relatif lebih baik. Hal ini ditandai dengan nilai akurasi, precision dan recall yang lebih tinggi jika dibandingkan dengan nilai yang dihasilkan saat menggunakan Multinomial NB. Namun, secara keseluruhan performa dari model Decision Tree Classifier pun masih belum sempurna karena nilainya masih relatif rendah. Hal ini dapat ditingkatkan melalui penggunaan cross validation, pemilihan fitur yang lebih prediktif, feature engineering, atau juga dapat dilakukan parameter tuning untuk mendapat hasil yang lebih baik."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "A31j8hR_G-aO"
      },
      "source": [
        "# B. Klasifikasi Emosi pada Tweet Bahasa \n",
        "\n",
        "Pada tutorial ini, kita akan mengklasifikan <i>tweet</i> Bahasa Indonesia ke dalam lima kelas emosi yaitu senang, cinta, marah, sedih, dan takut. <i>Dataset</i> yang digunakan dalam percobaan ini didapatkan dari <i>paper</i> berikut:\n",
        "\n",
        "Mei Silvana Saputri, Rahmad Mahendra, and Mirna Adriani, <i>Emotion Classification on Indonesian Twitter Dataset</i>.  International Conference on Asian Language Processing (IALP) 2018. Bandung. 2018. \n",
        "\n",
        "<i>Dataset</i> terdiri dari 4.403 <i>tweet</i> yang sudah dilakukan <i>pre-processing</i> dengan ketentuan sebagai berikut:\n",
        "* <i>Username</i> dan <i>mention</i> (ditandai dengan @) diganti dengan kata [USERNAME]\n",
        "* URL/<i>hyperlink</i> (http:// atau https://..) diganti dengan kata [URL]\n",
        "* Nomor sensitif, misalnya nomor telepon, nomor <i>invoice</i>, dan nomor pelacakan jasa pengiriman diganti dengan kata [SENSITIVE-NO]\n",
        "\n",
        "<i>Dataset</i> ini memuat <i>tweet</i> beremosi eksplisit dan implisit. Tabel 2 menunjukkan contoh <i>tweet</i> beremosi eksplisit dan implisit.\n",
        "\n",
        "Tabel 2. Contoh Data Emosi Eksplisit dan Emosi Implisit\n",
        "\n",
        "| Emosi Eksplisit | Emosi Implisit |\n",
        "|------|------|\n",
        "|hari ini libur, rencananya mau nonton Jurassic World, tapi kayanya gajadi deh mengingat kondisi yg gak fit bgt ini <b>sebel</b>. Rusak rencana sebelanga.. <b>sebel</b> akutu <font color='blue'>(marah)</font>|Ini aja membuktikan anda sudah TIDAK BENAR....!!! MASA NAPI KORUPTOR BISA PUNYA HP DI PENJARA ITU SDH MELANGGAR ATURAN.... DAN ANDA DG ENAKNYA MELANGGAR ATURAN...!! INI MENANDAKAN BAHWA ITULAH KARAKTER ANDA <font color='blue'>(marah)</font>|\n",
        "\n",
        "Untuk mengklasifikan <i>tweet</i> menjadi lima kelas emosi, dilakukan ekstraksi 4 fitur berikut:\n",
        "* Fitur Bag-of-words (unigram)\n",
        "* Fitur Sentimen Lexicon\n",
        "* Fitur POS Tag\n",
        "* Fitur Ortografi\n",
        "\n",
        "Langkah-langkah untuk melakukan klasifikasi emosi pada <i>dataset tweet</i> emosi tersebut adalah sebagai berikut:\n",
        "\n",
        "<b>1. Import library</b><br>\n",
        "<i>Library</i> yang digunakan pada tutorial ini antara lain pandas, numpy, nltk, Sastrawi, dan sklearn. \n",
        "\n",
        "<b>#Code 1</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejF0-Zk6-_yN",
        "outputId": "5c68c829-c533-49ca-9a47-40c9a262fdf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install Sastrawi\n",
        "!pip install nltk\n",
        "!pip install python-crfsuite"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Sastrawi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4b/bab676953da3103003730b8fcdfadbdd20f333d4add10af949dd5c51e6ed/Sastrawi-1.0.1-py2.py3-none-any.whl (209kB)\n",
            "\r\u001b[K     |█▋                              | 10kB 11.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Collecting python-crfsuite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: python-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:42:06.472963Z",
          "start_time": "2020-05-14T03:42:04.567313Z"
        },
        "id": "j4UnhombG-aO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import Sastrawi\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from nltk.tag import CRFTagger\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PT8HjEu_fCM",
        "outputId": "61b414ae-9a44-43e6-e3c8-f9e94845b8fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "AokiTGKs8zOf"
      },
      "source": [
        "<b>2. Membaca data</b><br>\n",
        "Data dibaca dengan <i>library</i> pandas.\n",
        "\n",
        "<b>#Code 2</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:42:06.653600Z",
          "start_time": "2020-05-14T03:42:06.478959Z"
        },
        "id": "-WRNfhrMG-aR",
        "outputId": "c1eda032-dd5a-45c5-8e55-09e63798646a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# membaca data\n",
        "raw_data = pd.read_csv(\"/content/drive/My Drive/dataset/Twitter_Emotion_Dataset.csv\",\n",
        "                       delimiter=\",\", encoding=\"Latin-1\")\n",
        "raw_data.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>anger</td>\n",
              "      <td>Soal jln Jatibaru,polisi tdk bs GERTAK gubernu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anger</td>\n",
              "      <td>Sesama cewe lho (kayaknya), harusnya bisa lebi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>happy</td>\n",
              "      <td>Kepingin gudeg mbarek Bu hj. Amad Foto dari go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>anger</td>\n",
              "      <td>Jln Jatibaru,bagian dari wilayah Tn Abang.Peng...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>happy</td>\n",
              "      <td>Sharing pengalaman aja, kemarin jam 18.00 bata...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                              tweet\n",
              "0  anger  Soal jln Jatibaru,polisi tdk bs GERTAK gubernu...\n",
              "1  anger  Sesama cewe lho (kayaknya), harusnya bisa lebi...\n",
              "2  happy  Kepingin gudeg mbarek Bu hj. Amad Foto dari go...\n",
              "3  anger  Jln Jatibaru,bagian dari wilayah Tn Abang.Peng...\n",
              "4  happy  Sharing pengalaman aja, kemarin jam 18.00 bata..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "rdMkBwTW8zOr"
      },
      "source": [
        "<b>3. Pra-pemrosesan data</b><br>\n",
        "Data Twitter bersifat <i>unstructured</i> dan memiliki format penulisan bebas (tidak sesuai kaidah penulisan yang benar). Oleh karena itu, dilakukan pra-pemrosesan data untuk melakukan normalisasi isi <i>tweet</i>. \n",
        "\n",
        "Dalam percobaan ini, dilakukan pra-pemrosesan berupa:\n",
        "\n",
        "    a. Normalisasi tweet\n",
        "    Normalisasi tweet terdiri dari pengubahan ke huruf kecil, pembuangan spasi yang berlebihan, trimming, pembuangan tanda baca, penghilangan huruf berulang (misalnya haiiii -> hai). Fungsi normalisasi (tweet) menerima input berupa satu buah tweet mentah bertipe string. \n",
        "\n",
        "<b>#Code 3a</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:42:11.091269Z",
          "start_time": "2020-05-14T03:42:11.082173Z"
        },
        "id": "RN0c_EEOG-aT"
      },
      "source": [
        "def normalisasi(tweet):\n",
        "    normal_tw = tweet.lower()  # lowercase\n",
        "    normal_tw = re.sub('\\s+', ' ', normal_tw)  # remove extra space\n",
        "    normal_tw = normal_tw.strip()  # trim depan belakang\n",
        "    normal_tw = re.sub(r'[^\\w\\s]', '', normal_tw)  # buang punctuation\n",
        "    # regex huruf yang berulang kaya haiiii (untuk fitur unigram)\n",
        "    normal_regex = re.compile(r\"(.)\\1{1,}\")\n",
        "    # buang huruf yang berulang\n",
        "    normal_tw = normal_regex.sub(r\"\\1\\1\", normal_tw)\n",
        "    return normal_tw"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-27T16:39:44.285857Z",
          "start_time": "2020-04-27T16:39:44.271983Z"
        },
        "editable": false,
        "id": "IKT_dkXy8zO0"
      },
      "source": [
        "    b. Pembuangan stopwords dan istilah spesial (username, hyperlink, sensitive-no)\n",
        "    Daftar stopwords didapatkan dari penelitian Tala.\n",
        "    \n",
        "    Tala, F. Z. (2003). A Study of Stemming Effects on Information Retrieval in Bahasa Indonesia. M.S. thesis. M.Sc. Thesis. Master of Logic Project. Institute for Logic, Language and Computation. Universiteti van Amsterdam The Netherlands.\n",
        "    \n",
        "    Fungsi remove_stopwords(tweet) menerima masukan berupa tweet yang sudah dinormalisasi yang bertipe string.\n",
        "    \n",
        "<b># Code 3b</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:43:54.967986Z",
          "start_time": "2020-05-14T03:43:54.954605Z"
        },
        "id": "M0VfpR9WG-aW"
      },
      "source": [
        "def remove_stopwords(tweet):\n",
        "    stopwords = pd.read_csv('/content/drive/My Drive/dataset/stopwords.csv', header=None)[0].values\n",
        "    special_list = ['username', 'url', 'sensitive-no']\n",
        "    token = nltk.word_tokenize(tweet)\n",
        "    token_afterremoval = []\n",
        "    for k in token:\n",
        "        if k not in stopwords and k not in special_list:\n",
        "            token_afterremoval.append(k)\n",
        "\n",
        "    str_clean = ' '.join(token_afterremoval)\n",
        "    return str_clean"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-27T16:43:16.134661Z",
          "start_time": "2020-04-27T16:43:16.130355Z"
        },
        "editable": false,
        "id": "qfcTtYBY8zO9"
      },
      "source": [
        "    c. Di luar tutorial ini Anda bisa mencoba opsi stemming pada tahap pra-pemrosesan. Fungsi stemming akan didefinisikan pada tutorial ini, namun tidak dijalankan. Fungsi stemming(tweet) menerima masukan berupa satu buah tweet bertipe string. \n",
        "\n",
        "<b>#Code 3c</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:43:57.175068Z",
          "start_time": "2020-05-14T03:43:57.163151Z"
        },
        "id": "fsQCAy0RG-aZ"
      },
      "source": [
        "def stemming(tweet):\n",
        "    token = nltk.word_tokenize(tweet)\n",
        "    stem_kalimat = []\n",
        "    for k in token:\n",
        "        factory = StemmerFactory()\n",
        "        stemmer = factory.create_stemmer()\n",
        "        stem_kata = stemmer.stem(clean_tw)\n",
        "        stem_kalimat.append(stem_kata)\n",
        "\n",
        "    stem_kalimat_str = ' '.join(stem_kalimat)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "CZr-CHG58zPF"
      },
      "source": [
        "    d. Pra-pemrosesan tweet secara keseluruhan\n",
        "    Pada tahap ini, akan dilakukan pemanggilan fungsi normalisasi dan remove_stopwords yang sudah didefinisikan sebelumnya. Setelah itu akan ditampilkan sampel tiga tweet pertama yang sudah dilakukan pra-pemrosesan. \n",
        "    \n",
        "<b>#Code 3d</b>    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:44:06.351202Z",
          "start_time": "2020-05-14T03:43:57.857163Z"
        },
        "id": "4f4UGYY9G-ac",
        "outputId": "5cae17c4-dcbf-41d7-d91f-c243a449e471",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def pra_pemrosesan(list_tweet):\n",
        "    tweet_clean = []\n",
        "    for tw in list_tweet:\n",
        "        normal_tweet = normalisasi(tw)\n",
        "        nosw_tweet = remove_stopwords(normal_tweet)\n",
        "        #stem_tweet = stemming(nosw_tweet)\n",
        "        tweet_clean.append(nosw_tweet)\n",
        "    return tweet_clean\n",
        "\n",
        "\n",
        "raw_tweet = raw_data['tweet']\n",
        "label = raw_data['label'].tolist()\n",
        "\n",
        "clean_tweet = pra_pemrosesan(raw_tweet)\n",
        "clean_tweet[:3]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jln jatibarupolisi tdk bs gertak gubernur emangny polisi tdk pmbhasan jgn berpolitik pengaturan wilayahhak gubernur tn abang turun temurunpelikperlu kesabaran',\n",
              " 'cewe lho kayaknya rasain sibuk jaga rasain sakitnya haid paniknya pulang malem gimana orang asing wajarlah korban takut curhat dibela dihujat',\n",
              " 'kepingin gudeg mbarek bu hj amad foto google sengaja biar temanteman jg membayangkannya berbagi indah']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "LJ0BQoQV8zPN"
      },
      "source": [
        "<b>4. Ekstraksi Fitur Bag-of-Words</b><br>\n",
        "Fitur Bag-of-Words atau <i>unigram</i> memuat informasi mengenai frekuensi kemunculan suatu kata di dokumen. Fitur <i>unigram</i> dibentuk menggunakan <i>library</i> $CountVectorizer$ dari $Scikit-learn$. Jumlah kata unik (<i>vocabulary</i>) yang terbentuk bergantung dari data yang digunakan. Tapi, dalam percobaan ini akan digunakan parameter max_features=2000 dimana akan diambil 2.000 kata unik yang memiliki frekuensi kemunculan tertinggi. \n",
        "\n",
        "<b>#Code 4</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:44:10.249625Z",
          "start_time": "2020-05-14T03:44:09.872089Z"
        },
        "id": "CU0frcVPG-af",
        "outputId": "a819dcf7-dc6f-48c6-8d53-b0902cc9b717",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def EkstraksiBoW(tweet):\n",
        "    unigram = CountVectorizer(ngram_range=(1, 1), max_features=2000)\n",
        "    unigram_matrix = unigram.fit_transform(np.array(tweet)).todense()\n",
        "    nama_fitur = unigram.get_feature_names()\n",
        "    return unigram_matrix, nama_fitur\n",
        "\n",
        "\n",
        "unigram_feat, feat_name = EkstraksiBoW(clean_tweet)\n",
        "print(unigram_feat[:3])\n",
        "print(feat_name[:10])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "['10', '100', '11', '12', '15', '20', '2016', '2017', '2018', '2019']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "C-4BTsO08zPS"
      },
      "source": [
        "<b>5. Ekstraksi Fitur Sentimen Leksikon (Kamus Sentimen)</b><br>\n",
        "Orientasi sentimen dapat digunakan sebagai fitur untuk klasifikasi. Pada tutorial ini, akan digunakan leksikon sentimen dari penelitian berikut ini:\n",
        "\n",
        "Clara Vania, Moh. Ibrahim, and Mirna Adriani. Sentiment Lexicon Generation for an Under-Resourced Language. CICLING 2014 (IJCLA)\n",
        "\n",
        "Daftar kata bersentimen positif terdapat pada <i>positif_vania.txt</i> dan daftar kata bersentimen negatif terdapat pada <i>negatif_vania.txt</i>. \n",
        "\n",
        "<b>#Code 5a</b><br>\n",
        "<i>Code</i> ini digunakan untuk mendefinisikan fungsi Ekstraksi Sentimen yang menerima input berupa daftar <i>tweet</i>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:44:20.458912Z",
          "start_time": "2020-05-14T03:44:20.442533Z"
        },
        "id": "8_TRwqq_G-ah"
      },
      "source": [
        "def EkstraksiSentimen(list_tweet):\n",
        "    pos = pd.read_csv(\"/content/drive/My Drive/dataset/positif_vania.txt\", header=None, names=['pos'])\n",
        "    list_pos = pos['pos'].tolist()\n",
        "    neg = pd.read_csv(\"/content/drive/My Drive/dataset/negatif_vania.txt\", header=None, names=['neg'])\n",
        "    list_neg = neg['neg'].tolist()\n",
        "\n",
        "    fitur_sentimen_all = []\n",
        "    for tweet in list_tweet:\n",
        "        # inisiasi value\n",
        "        emosi = [\"positif\", \"negatif\"]\n",
        "        value = [0, 0]\n",
        "        emosi_value = {}\n",
        "        for i in range(len(emosi)):\n",
        "            emosi_value[emosi[i]] = value[i]\n",
        "\n",
        "        list_kata = tweet.split()\n",
        "        for k in list_kata:\n",
        "            if k in list_pos:\n",
        "                emosi_value[\"positif\"] += 1\n",
        "            if k in list_neg:\n",
        "                emosi_value[\"negatif\"] += 1\n",
        "\n",
        "        fitur_sentimen_perkalimat = list(emosi_value.values())\n",
        "        fitur_sentimen_all.append(fitur_sentimen_perkalimat)\n",
        "\n",
        "    return fitur_sentimen_all"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "4SUTclmq8zPe"
      },
      "source": [
        "<b>#Code 5b</b><br>\n",
        "Pemanggilan fungsi $EkstraksiSentimen$ dan menampilkan sampel hasil ekstraksi. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:44:22.597669Z",
          "start_time": "2020-05-14T03:44:21.640636Z"
        },
        "id": "Z6kePED1G-ak",
        "outputId": "b9ae7d9d-1ea1-40a0-ba53-a0d1720a4be6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentlex_feat = EkstraksiSentimen(clean_tweet)\n",
        "print(sentlex_feat[:10])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 0], [0, 2], [1, 0], [0, 0], [1, 0], [0, 2], [0, 0], [0, 0], [0, 1], [0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "v1DBie5V8zPr"
      },
      "source": [
        "<b>6. Ekstraksi Fitur Part-Of-Speech Tag</b><br>\n",
        "<i>Part-of-speech</i> (POS) merupakan kelas kata yang dapat digunakan untuk mengenali emosi pada <i>tweet</i>. Pada percobaan ini, akan dihitung kemunculan kata sifat (JJ) dan kata negasi (NEG) berdasarkan <i>pre-trained</i> POS Tag dari penelitian Dinakarami et. al. yang sudah dikonversi ke dalam bentuk CRF Tagger agar bisa dibaca dari NLTK. \n",
        "\n",
        "Arawinda Dinakaramani, Fam Rashel, Andry Luthfi, and Ruli Manurung. <i>Designing an Indonesian Part of speech Tagset and Manually Tagged Indonesian Corpus</i>. International Conference on Asian Language Processing (IALP 2014). Kuching, 20-22 October 2014.\n",
        "\n",
        "<i>Raw data pre-trained</i> POS Tag yang belum ditransformasi ke dalam bentuk CRF Tagger bisa didapatkan di Fam Rashel’s <a href='https://github.com/famrashel/idn-tagged-corpus'>Github</a>. \n",
        "\n",
        "<b>#Code 6a</b><br>\n",
        "Mendefinisikan fungsi $EkstraksiPOS$ yang menerima masukan berupa daftar <i>tweet</i>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:44:24.459299Z",
          "start_time": "2020-05-14T03:44:24.445467Z"
        },
        "id": "oCI1qDZkG-am"
      },
      "source": [
        "def EkstraksiPOS(list_tweet):\n",
        "    ct = CRFTagger()\n",
        "    ct.set_model_file(\"/content/drive/My Drive/dataset/all_indo_man_tag_corpus_model.crf.tagger\")\n",
        "    pos_feat_list = []\n",
        "    count_tag = []\n",
        "    for tweet in list_tweet:\n",
        "        token = nltk.word_tokenize(tweet)\n",
        "        tag = ct.tag_sents([token])\n",
        "        flat_tag = [item for sublist in tag for item in sublist]\n",
        "        pos_count = Counter([j for i, j in flat_tag])\n",
        "        pos_feat = (pos_count['JJ'], pos_count['NEG'])\n",
        "        pos_feat_list.append(pos_feat)\n",
        "    return pos_feat_list"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "FCteXK9n8zPy"
      },
      "source": [
        "<b>#Code 6b</b><br>\n",
        "Memanggil fungsi $EkstraksiPOS$ dan menampilkan sampel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:44:27.006363Z",
          "start_time": "2020-05-14T03:44:25.859378Z"
        },
        "id": "gzc7yD5SG-as",
        "outputId": "0ada52bb-0ecf-4161-b4eb-5705eadf0734",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "postag_feat = EkstraksiPOS(clean_tweet)\n",
        "print(postag_feat[:3])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0), (5, 0), (1, 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-27T17:08:56.890723Z",
          "start_time": "2020-04-27T17:08:56.878954Z"
        },
        "editable": false,
        "id": "vOCP-Q3k8zP9"
      },
      "source": [
        "<b>7. Ekstraksi Fitur Ortografi</b><br>\n",
        "Pada percobaan ini, fitur ortografi yang digunakan sebagai fitur untuk mengenali emosi pada <i>tweet</i> yaitu jumlah huruf kapital, jumlah tanda seru, jumlah huruf dan panjang karakter. Oleh karena itu, <i>dataset</i> yang digunakan untuk menghasilkan fitur ortografi merupakan dataset awal yang belum mengalami pra-pemrosesan. \n",
        "\n",
        "<b>#Code 7a</b><br>\n",
        "Mendefinisikan fungsi $EkstraksiOrtografi$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:44:28.278975Z",
          "start_time": "2020-05-14T03:44:28.265150Z"
        },
        "id": "9n2_66w3G-aw"
      },
      "source": [
        "def EkstraksiOrtografi(raw_tweet):\n",
        "    all_orto_feat = []\n",
        "    for tw in raw_tweet:\n",
        "        capital_count = sum(1 for c in tw if c.isupper())\n",
        "        exclamation_count = sum((1 for c in tw if c == \"!\"))\n",
        "        word_len = len(nltk.word_tokenize(tw))\n",
        "        char_len = len(tw)\n",
        "        orto_feat = [capital_count, exclamation_count, word_len, char_len]\n",
        "        all_orto_feat.append(orto_feat)\n",
        "    return all_orto_feat"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5DpymXS8zQC"
      },
      "source": [
        "<b>#Code 7b</b><br>\n",
        "Memanggil fungsi EkstraksiPOS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:44:30.654600Z",
          "start_time": "2020-05-14T03:44:29.484265Z"
        },
        "id": "AFxydYvsG-az",
        "outputId": "2b125621-c2e9-47da-ac50-292e0bdd1958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "orto_feat = EkstraksiOrtografi(raw_tweet)\n",
        "orto_feat[:3]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[35, 0, 41, 220], [3, 0, 44, 235], [5, 0, 22, 116]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "wsl8Ss0T8zQN"
      },
      "source": [
        "<b>8. Klasifikasi</b><br>\n",
        "Pada percobaan ini, klasifikasi dilakukan dengan menggunakan algoritma Multinomial Naïve Bayes. Pembagian data training dan testing digunakan menggunakan model k-fold Cross Validation dengan nilai $k = 10$. Dengan model Cross-Validation, proses training dan testing akan dilakukan sebanyak $k$ kali dengan pembagian data yang berbeda. \n",
        "\n",
        "<b>#Code 8</b><br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-14T03:44:33.242188Z",
          "start_time": "2020-05-14T03:44:31.354925Z"
        },
        "id": "YdcnTcRtG-a1",
        "outputId": "4484621f-d89c-4c14-f72f-232eaf34d707",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "feat_list = [unigram_feat, sentlex_feat, postag_feat, orto_feat]\n",
        "feat_name = [\"Unigram\", \"Sentimen\", \"POS\", \"Ortografi\"]\n",
        "for f, n in zip(feat_list, feat_name):\n",
        "    X = f\n",
        "    y = label\n",
        "    scoring = ['accuracy', 'f1_macro']\n",
        "    nb = MultinomialNB()\n",
        "    scores = cross_validate(nb, X, y, cv=10, scoring=scoring)\n",
        "    acc = np.mean(scores['test_accuracy'])\n",
        "    f1 = np.mean(scores['test_f1_macro'])\n",
        "    print(\"Jenis Fitur : \", n)\n",
        "    print(\"Akurasi :\", acc)\n",
        "    print(\"F1-Score :\", f1)\n",
        "    print(\"---------------\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jenis Fitur :  Unigram\n",
            "Akurasi : 0.6162280972995259\n",
            "F1-Score : 0.6164587333032618\n",
            "---------------\n",
            "Jenis Fitur :  Sentimen\n",
            "Akurasi : 0.3149299113584828\n",
            "F1-Score : 0.17759729296827526\n",
            "---------------\n",
            "Jenis Fitur :  POS\n",
            "Akurasi : 0.2503973407544836\n",
            "F1-Score : 0.08046097167342903\n",
            "---------------\n",
            "Jenis Fitur :  Ortografi\n",
            "Akurasi : 0.299930426716141\n",
            "F1-Score : 0.1940956956279642\n",
            "---------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": false,
        "id": "AUSzhUne8zQT"
      },
      "source": [
        "<b><font color='red'>Tugas Tutorial B</font></b>\n",
        "1. Menurut pemahaman Anda, apa yang dimaksud dengan fitur ortografi?\n",
        "2. Buatlah fitur lain yang dapat diekstrak dari <i>dataset</i>.<br><i>Hint</i>: terdapat leksikon lainnya yang dapat digunakan untuk mengekstraksi fitur sentimen leksikon yang baru, seperti <a href='https://github.com/fajri91/InSet'>InSet</a> dan <a href='https://github.com/masdevid/sentistrength_id'>sentistrength_id</a>. \n",
        "3. Gunakan algoritma Decision Tree untuk  melakukan klasifikasi emosi dengan kombinasi 2 fitur dari 4 fitur yang sudah kita ekstraksi sebelumnya (unigram, sentimen leksikon, POS Tag dan ortografi). Anda bebas memilih 3 kombinasi fitur (misal: [unigram, POS Tag], [unigram, sentimen leksikon], dan [unigram, ortografi]). Gunakan F1-Score sebagai metrik evaluasi. Tampilkan hasil percobaan pada tabel, sebagai contoh:\n",
        "\n",
        "|Kombinasi Fitur|F1-Score|\n",
        "|------|------|\n",
        "|[unigram, POS Tag]|------|\n",
        "|[unigram, sentimen leksikon]|------|\n",
        "|[unigram, ortografi]|------|\n",
        "\n",
        "    Lakukan analisis dari hasil yang didapatkan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjmS-MmDMOxW"
      },
      "source": [
        "**Jawaban Tugas B**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjxTq3o6MTAY"
      },
      "source": [
        "**No. 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzWTqbw8NDgK"
      },
      "source": [
        "Fitur ortografi digunakan untuk mengekstraksi emosi seseorang yang mungkin tersirat melalui cara menuliskan tweet-nya. Contohnya, seseorang yang sedang marah bisa diasosiasikan dengan banyaknya penggunaan tanda seru atau banyaknya penggunaan huruf kapital. Dengan ortografi maka emosi tersebut dapat di-capture dan dijadikan sebagai salah satu input yang mungkin akan berguna dalam pengolahan data selanjutnya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4arT_CAOkK6"
      },
      "source": [
        "**No. 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqJwYqhMMa7W"
      },
      "source": [
        "def EkstraksiInSetLexicon(list_tweet):\n",
        "    pos_url = 'https://raw.githubusercontent.com/fajri91/InSet/master/positive.tsv'\n",
        "    neg_url = 'https://raw.githubusercontent.com/fajri91/InSet/master/negative.tsv'\n",
        "    inset_pos = pd.read_csv(pos_url, delimiter='\\t', header=0)\n",
        "    inset_list_pos_words = inset_pos['word'].tolist()\n",
        "    inset_list_pos_weights = inset_pos['weight'].tolist()\n",
        "    inset_pos_dict = dict(zip(inset_list_pos_words, inset_list_pos_weights))\n",
        "    inset_neg = pd.read_csv(neg_url, delimiter='\\t', header=0)\n",
        "    inset_list_neg_words = inset_neg['word'].tolist()\n",
        "    inset_list_neg_weights = inset_neg['weight'].tolist()\n",
        "    inset_neg_dict = dict(zip(inset_list_neg_words, inset_list_neg_weights))\n",
        "\n",
        "    inset_fitur_sentimen_all = []\n",
        "    for tweet in list_tweet:\n",
        "        # inisiasi value\n",
        "        emosi = [\"positif\", \"negatif\"]\n",
        "        value = [0, 0]\n",
        "        emosi_value = {}\n",
        "        for i in range(len(emosi)):\n",
        "            emosi_value[emosi[i]] = value[i]\n",
        "\n",
        "        list_kata = tweet.split()\n",
        "        for k in list_kata:\n",
        "            emosi_value[\"positif\"] += inset_pos_dict.get(k, 0)\n",
        "            emosi_value[\"negatif\"] += inset_neg_dict.get(k, 0)\n",
        "\n",
        "        fitur_sentimen_perkalimat = list(emosi_value.values())\n",
        "        inset_fitur_sentimen_all.append(fitur_sentimen_perkalimat)\n",
        "\n",
        "    return inset_fitur_sentimen_all"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYucVskIWfzu",
        "outputId": "5256e338-803d-40a3-cab8-56554c717d0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inset_feat = EkstraksiInSetLexicon(clean_tweet)\n",
        "print(inset_feat[:10])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6, -8], [9, -31], [9, -7], [0, -2], [12, -5], [18, -25], [3, -5], [11, -12], [15, -13], [10, -14]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5AU3Ht2UpPf"
      },
      "source": [
        "**No. 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa102S5-dACI"
      },
      "source": [
        "Kombinasi 2 fitur yang dipilih dari keempat fitur adalah **[Unigram + Sentimen Leksikon]**, **[Sentimen Leksikon + Ortografi]**, dan **[Unigram + Ortografi]**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ssFtJCqWqpR",
        "outputId": "2a2b0a09-3773-4e9c-d822-8c401ad62d95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "unigram_sentlex = np.hstack((unigram_feat, sentlex_feat))\n",
        "sentlex_orto = np.hstack((sentlex_feat, orto_feat))\n",
        "unigram_postag = np.hstack((unigram_feat, postag_feat))\n",
        "\n",
        "combined_feat_list = [unigram_sentlex, sentlex_orto, unigram_postag]\n",
        "combined_feat_name = [\"[Unigram, Sentimen Leksikon]\", \"[Sentimen Leksikon, Ortografi]\", \"[Unigram, Pos Tagging]\"]\n",
        "f1_scores = []\n",
        "\n",
        "for f, n in zip(combined_feat_list, combined_feat_name):\n",
        "    X = f\n",
        "    y = label\n",
        "    dec_tree = DecisionTreeClassifier()\n",
        "    scoring = ['accuracy', 'f1_macro']\n",
        "    scores = cross_validate(dec_tree, X, y, cv=10, scoring=scoring)\n",
        "    f1 = np.mean(scores['test_f1_macro'])\n",
        "    f1_scores.append(f1)\n",
        "    print(\"Jenis Fitur : \", n)\n",
        "    print(\"F1-Score :\", f1)\n",
        "    print(\"---------------\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jenis Fitur :  [Unigram, Sentimen Leksikon]\n",
            "F1-Score : 0.5148425380536806\n",
            "---------------\n",
            "Jenis Fitur :  [Sentimen Leksikon, Ortografi]\n",
            "F1-Score : 0.2840039673088317\n",
            "---------------\n",
            "Jenis Fitur :  [Unigram, Pos Tagging]\n",
            "F1-Score : 0.5414688852961591\n",
            "---------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJvWpVAMdUP2"
      },
      "source": [
        "**Tabel Hasil F1-Score Kombinasi 2-Fitur**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEj00kkrmFEI",
        "outputId": "6bb27af5-7b30-4f87-bc82-157b14c41035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "pd.DataFrame(list(zip(combined_feat_name,f1_scores)), columns=['Kombinasi Fitur','F1-score'])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kombinasi Fitur</th>\n",
              "      <th>F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Unigram, Sentimen Leksikon]</td>\n",
              "      <td>0.514843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Sentimen Leksikon, Ortografi]</td>\n",
              "      <td>0.284004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Unigram, Pos Tagging]</td>\n",
              "      <td>0.541469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Kombinasi Fitur  F1-score\n",
              "0    [Unigram, Sentimen Leksikon]  0.514843\n",
              "1  [Sentimen Leksikon, Ortografi]  0.284004\n",
              "2          [Unigram, Pos Tagging]  0.541469"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McgkyZ2od9s4"
      },
      "source": [
        "Dari tabel hasil F1-score masing-masing kombinasi fitur, dapat dilihat karena sejak awal Unigram merupakan fitur yang paling deskriptif saat digunakan sebagai fitur tunggal menggunakan Multinomial Naive Bayes Classifier (F1-score ~0.60) maka kombinasi yang melibatkan Unigram memiliki F1-score yang cukup baik. Dari kombinasi Unigram dengan Sentimen Leksikon diperoleh F1-score bernilai ~0.51 dimana lebih rendah dari saat penggunaan Unigram sebagai fitur tunggal. Untuk Sentimen Leksikon dan Ortografi, ketika digunakan sebagai fitur tunggal menggunakan Multinomial Naive Bayes Classifier menghasilkan F1-score yang relatif serupa yaitu ~0.30, namun ketika dikombinasikan dengan Decision Tree Classifier justru menurunkan nilai menjadi ~0.27. Terakhir, kombinasi Unigram dan POS Tagging menghasilkan F1-score yang lumayan baik dengan nilai ~0.54, namun masih lebih rendah daripada saat menggunakan Unigram sebagai fitur tunggal menggunakan Multinomial Naive Bayes Classifier. \n",
        "<br/><br/>\n",
        "Dari hasil di atas dapat diketahui bahwa Unigram merupakan fitur yang paling prediktif di antara keempat fitur. Namun, apabila dikombinasikan menjadi pasangan fitur bersama Sentimen Leksikon maupun POS Tagging menggunakan Decision Tree Classifier justru menurunkan nilai F1-score-nya. Hal ini juga dapat disebabkan karena nilai F1-score Sentimen Leksikon, Ortografi dan POS Tagging ketika digunakan sebagai fitur tunggal menghasilkan nilai yang tidak terlalu bagus. Perbedaan nilai antara ketika menggunakan fitur tunggal dengan fitur kombinasi ini kemungkinan dapat disebabkan oleh antara lain perbedaan classifier yang digunakan, fitur yang memang kurang prediktif, kombinasi fitur yang belum optimal, dan lainnya."
      ]
    }
  ]
}